{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c37b7cb-9780-401a-b802-3e9c7c23c8c2",
   "metadata": {},
   "source": [
    "**Q1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8887e9ff-dca7-48ce-b029-3fd07bc60876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34859059-76cd-4484-825b-f8c4fe221b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.078222655\n"
     ]
    }
   ],
   "source": [
    "model_name = \"multi-qa-distilbert-cos-v1\"\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "user_question_embedding = embedding_model.encode(user_question)\n",
    "\n",
    "print(user_question_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f1e70be-4734-408b-aa16-20cdb4405660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_model.encode(\"I just discovered the course. Can I still join it?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d457509-3356-40d5-9af3-463cee2a716b",
   "metadata": {},
   "source": [
    "**Q2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca8d327-90e4-4732-8db1-83b248ecc1e5",
   "metadata": {},
   "source": [
    "Create embeddings for documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f5e728-b67e-4cba-aa0d-f0813210a345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 768)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()\n",
    "\n",
    "# Filter documents for \"machine-learning-zoomcamp\"\n",
    "filtered_documents = [doc for doc in documents if doc['course'] == 'machine-learning-zoomcamp']\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = []\n",
    "for doc in filtered_documents:\n",
    "    qa_text = f\"{doc['question']} {doc['text']}\"\n",
    "    embedding = embedding_model.encode(qa_text)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "X = np.array(embeddings)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a15b1-2f69-4faf-92d3-d9689cb81244",
   "metadata": {},
   "source": [
    "**Q3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80813ed8-7e2f-4f96-b645-d42b85ab1883",
   "metadata": {},
   "source": [
    "Compute the cosine similarity between the query vector and the document embeddings. \n",
    "The vectors returned from the embedding model are already normalized, so we can simply multiply the matrix `X` by the query vector `v` to get the similarity scores.\n",
    "\n",
    "The highest score in the results indicates the most similar document to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd7987c-f3ff-4695-b8c5-2509064919d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6506573\n"
     ]
    }
   ],
   "source": [
    "v = user_question_embedding\n",
    "scores = X.dot(v)\n",
    "print(np.max(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0be07e-a6da-4f0e-be39-f12c19efea77",
   "metadata": {},
   "source": [
    "**Q4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9812aee1-80c7-4bcb-b7ef-b10104f6d484",
   "metadata": {},
   "source": [
    "Compute the similarity between a query vector and all the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8662b5-3592-4d40-a03c-edc82eac4e27",
   "metadata": {},
   "source": [
    "We load the ground truth dataset, which contains the correct document IDs for a set of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a2452b9-2a84-47e2-b8bd-3dc9eda5e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f3bb32-3d4f-4724-96c7-6190136082c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argpartition(-scores, num_results)[:num_results]\n",
    "        top_idx = idx[np.argsort(-scores[idx])]  # Sort the top `num_results` scores\n",
    "        return [self.documents[i] for i in top_idx]\n",
    "\n",
    "# Create the search engine instance with the filtered documents and embeddings\n",
    "search_engine = VectorSearchEngine(documents=filtered_documents, embeddings=X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f738b-0e77-49f8-8f46-2b48267f5889",
   "metadata": {},
   "source": [
    "np.argpartition: Partially sorts the array to get the top num_results elements. These elements are not guaranteed to be in order.\n",
    "\n",
    "np.argsort on the top results: Fully sorts these top elements to ensure they are in the correct order. This sorting is crucial for MRR, which depends on the exact ranking of the results.\n",
    "\n",
    "To achieve correct MRR, we should sort the top results to ensure they are in the correct order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e12e5-ec5d-49f6-8b54-376a4cd46fff",
   "metadata": {},
   "source": [
    "To evaluate the performance of our search engine, we use the hit-rate metric. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c89522e2-ccc7-44ea-808e-a4450179b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt += 1\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score += 1 / (rank + 1)\n",
    "    return total_score / len(relevance_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f5742c7-ce1d-4ec7-afeb-b880762f6fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def evaluate_custom_search_engine(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for q in tqdm(ground_truth, desc=\"Evaluating search engine\"):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "    \n",
    "    hit_rate_result = hit_rate(relevance_total)\n",
    "    mrr_result = mrr(relevance_total)\n",
    "    print(f\"Evaluation completed in {time.time() - start_time:.2f} seconds\")\n",
    "    return {\n",
    "        'hit_rate': hit_rate_result,\n",
    "        'mrr': mrr_result,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9425621e-4862-4254-9b48-9d403b145169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(q):\n",
    "    question = q['question']\n",
    "    v_query = embedding_model.encode(question)\n",
    "    return search_engine.search(v_query, num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e3165cc-9e83-4633-804c-d3f8d6abf234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating search engine: 100%|█████████████████████████████████████████████████████████████████████████████████████| 1830/1830 [01:29<00:00, 20.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed in 89.89 seconds\n",
      "Hit rate: 0.9398907103825137\n",
      "MRR: 0.8516484517304189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # Create the search engine instance with the filtered documents and embeddings\n",
    "# search_engine = VectorSearchEngine(documents=filtered_documents, embeddings=X)\n",
    "\n",
    "# Evaluate the search engine\n",
    "evaluation_results_custom  = evaluate_custom_search_engine(ground_truth, search_query)\n",
    "print(f\"Hit rate: {evaluation_results_custom['hit_rate']}\")\n",
    "print(f\"MRR: {evaluation_results_custom['mrr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf519e-36fc-4d32-9b14-2862a55daab8",
   "metadata": {},
   "source": [
    "**Q5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728215c9-7156-4a3c-af9e-caa6ee7f6f82",
   "metadata": {},
   "source": [
    "Run Elasticsearch from Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eb3758-4565-431e-a320-5e3656bff5f0",
   "metadata": {},
   "source": [
    "Index the documents with Elasticsearch with specific settings and mappings, including dense vector fields for the embeddings.\n",
    "\n",
    "After indexing, perform a search for the same query from Q1 using Elasticsearch. The ID of the document with the highest score is noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1be58a5f-3335-4dba-a0e6-7d4abbb159e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "644302e5-f7b4-4082-92ef-256501a8254c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 375/375 [01:16<00:00,  4.93it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(filtered_documents, desc=\"Indexing documents\"):\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    qt = question + ' ' + text\n",
    "\n",
    "    doc['question_text_vector'] = embedding_model.encode(qt).tolist()\n",
    "\n",
    "    es_client.index(index=index_name, id=doc['id'], body=doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98424c3c-3918-49b4-a838-9b6b8fa699b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: ee58a693, Score: 0.82532895, Question: The course has already started. Can I still join it?\n",
      "ID: 0a278fb2, Score: 0.73585373, Question: I just joined. What should I do next? How can I access course materials?\n",
      "ID: 6ba259b1, Score: 0.7295, Question: I filled the form, but haven't received a confirmation email. Is it normal?\n",
      "ID: 9f261648, Score: 0.72849524, Question: Can I do the course in other languages, like R or Scala?\n",
      "ID: e7ba6b8a, Score: 0.7252791, Question: The course videos are from the previous iteration. Will you release new ones or we’ll use the videos from 2021?\n"
     ]
    }
   ],
   "source": [
    "def elastic_search_knn(field, vector, course):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(index=index_name, body=search_query)\n",
    "    return es_results['hits']['hits']\n",
    "\n",
    "# Perform the search\n",
    "query = 'I just discovered the course. Can I still join it?'\n",
    "v_q = embedding_model.encode(query).tolist()\n",
    "response = elastic_search_knn('question_text_vector', v_q, 'machine-learning-zoomcamp')\n",
    "\n",
    "# Print the results\n",
    "for hit in response:\n",
    "    print(f\"ID: {hit['_id']}, Score: {hit['_score']}, Question: {hit['_source']['question']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98059610-aed6-43a5-ba86-5c23ca880613",
   "metadata": {},
   "source": [
    "**Q6**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce102a33-390f-4814-a32d-9b5e6c455ec3",
   "metadata": {},
   "source": [
    "Evaluate the hit-rate for Elasticsearch. \n",
    "\n",
    "Load the ground truth dataset again and use a function to perform the search with Elasticsearch. \n",
    "\n",
    "The hit-rate is calculated in the same way as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db6c08e6-ab59-42b6-ac39-8a3010a3677f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Where can I sign up for the course?', 'course': 'machine-learning-zoomcamp', 'document': '0227b872'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "print(ground_truth[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f21869f6-43b6-4310-99ee-a78dc28cc59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt += 1\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def calculate_mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score += 1 / (rank + 1)\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7096b79-9a28-4898-9b13-706cf272a36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Elasticsearch: 100%|█████████████████████████████████████████████████████████████████████████████████████| 1830/1830 [01:27<00:00, 20.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed in 87.35 seconds\n",
      "Elasticsearch - Hit rate: 0.9398907103825137\n",
      "Elasticsearch - MRR: 0.8504462659380693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_elasticsearch(ground_truth):\n",
    "    relevance_total = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for q in tqdm(ground_truth, desc=\"Evaluating Elasticsearch\"):\n",
    "        question = q['question']\n",
    "        relevant_doc_id = q['document']\n",
    "        query_embedding = embedding_model.encode(question).tolist()\n",
    "        results = elastic_search_knn('question_text_vector', query_embedding, q['course'])\n",
    "        \n",
    "        relevance = []\n",
    "        for res in results:\n",
    "            # Debug print for each result\n",
    "            if '_source' in res and 'id' in res['_source']:\n",
    "                relevance.append(res['_source']['id'] == relevant_doc_id)\n",
    "            else:\n",
    "                relevance.append(False)\n",
    "                \n",
    "        relevance_total.append(relevance)\n",
    "    \n",
    "    hit_rate_result = calculate_hit_rate(relevance_total)\n",
    "    mrr_result = calculate_mrr(relevance_total)\n",
    "    print(f\"Evaluation completed in {time.time() - start_time:.2f} seconds\")\n",
    "    return {\n",
    "        'hit_rate': hit_rate_result,\n",
    "        'mrr': mrr_result,\n",
    "    }\n",
    "\n",
    "# Evaluate Elasticsearch\n",
    "evaluation_results_elastic = evaluate_elasticsearch(ground_truth)\n",
    "print(f\"Elasticsearch - Hit rate: {evaluation_results_elastic['hit_rate']}\")\n",
    "print(f\"Elasticsearch - MRR: {evaluation_results_elastic['mrr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d89bbf-eec9-40fb-b861-08c210e430cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
